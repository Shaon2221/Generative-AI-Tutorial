{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating example restaurant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurant data CSV file has been generated.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "# Function to generate random reviews\n",
    "def generate_reviews():\n",
    "    positive = [\"Delicious!\", \"Great taste!\", \"Highly recommended!\", \"Amazing flavor!\"]\n",
    "    negative = [\"Disappointing\", \"Not worth it\", \"Could be better\", \"Mediocre\"]\n",
    "    return \", \".join(random.choices(positive + negative, k=random.randint(1, 3)))\n",
    "\n",
    "# Generate restaurant data\n",
    "items = [\n",
    "    \"Margherita Pizza\", \"Pepperoni Pizza\", \"Vegetarian Pizza\", \"Hawaiian Pizza\",\n",
    "    \"Spaghetti Carbonara\", \"Fettuccine Alfredo\", \"Lasagna\", \"Chicken Parmesan\",\n",
    "    \"Caesar Salad\", \"Greek Salad\", \"Tiramisu\", \"Chocolate Mousse\"\n",
    "]\n",
    "\n",
    "with open('restaurant_data.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Item\", \"Description\", \"Price\", \"Availability\", \"Reviews\"])\n",
    "    \n",
    "    for item in items:\n",
    "        description = f\"Delicious {item.lower()} made with fresh ingredients\"\n",
    "        price = round(random.uniform(8.99, 24.99), 2)\n",
    "        availability = random.choice([\"In Stock\", \"Low Stock\", \"Out of Stock\"])\n",
    "        reviews = generate_reviews()\n",
    "        \n",
    "        writer.writerow([item, description, price, availability, reviews])\n",
    "\n",
    "print(\"Restaurant data CSV file has been generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order Placement Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"order_id\": \"ORD-20240908174636\",\n",
      "  \"customer_name\": \"John Doe\",\n",
      "  \"customer_address\": \"123 Main St, Anytown, USA\",\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"name\": \"Margherita Pizza\",\n",
      "      \"price\": 12.99,\n",
      "      \"quantity\": 2\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Caesar Salad\",\n",
      "      \"price\": 8.99,\n",
      "      \"quantity\": 1\n",
      "    }\n",
      "  ],\n",
      "  \"total_amount\": 34.97,\n",
      "  \"order_date\": \"2024-09-08T17:46:36.544058\",\n",
      "  \"status\": \"Placed\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def place_order(items, customer_name, customer_address):\n",
    "    order = {\n",
    "        \"order_id\": f\"ORD-{datetime.now().strftime('%Y%m%d%H%M%S')}\",\n",
    "        \"customer_name\": customer_name,\n",
    "        \"customer_address\": customer_address,\n",
    "        \"items\": items,\n",
    "        \"total_amount\": sum(item[\"price\"] * item[\"quantity\"] for item in items),\n",
    "        \"order_date\": datetime.now().isoformat(),\n",
    "        \"status\": \"Placed\"\n",
    "    }\n",
    "    return json.dumps(order, indent=2)\n",
    "\n",
    "# Example usage\n",
    "sample_order = place_order(\n",
    "    items=[\n",
    "        {\"name\": \"Margherita Pizza\", \"price\": 12.99, \"quantity\": 2},\n",
    "        {\"name\": \"Caesar Salad\", \"price\": 8.99, \"quantity\": 1}\n",
    "    ],\n",
    "    customer_name=\"John Doe\",\n",
    "    customer_address=\"123 Main St, Anytown, USA\"\n",
    ")\n",
    "\n",
    "print(sample_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Database Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "/Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "I0000 00:00:1725796178.390779 10816432 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector database has been set up successfully.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Load restaurant data\n",
    "def load_restaurant_data(file_path='restaurant_data.csv'):\n",
    "    with open(file_path, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        return list(reader)\n",
    "\n",
    "# Create documents from restaurant data\n",
    "def create_documents(data):\n",
    "    documents = []\n",
    "    for item in data:\n",
    "        content = f\"Item: {item['Item']}\\nDescription: {item['Description']}\\nPrice: ${item['Price']}\\nAvailability: {item['Availability']}\\nReviews: {item['Reviews']}\"\n",
    "        documents.append(Document(page_content=content, metadata={\"item\": item['Item']}))\n",
    "    return documents\n",
    "\n",
    "# Set up vector database\n",
    "def setup_vector_db():\n",
    "    # Load data\n",
    "    restaurant_data = load_restaurant_data()\n",
    "    documents = create_documents(restaurant_data)\n",
    "\n",
    "    # Initialize HuggingFace embeddings\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "    # Create Chroma vector store\n",
    "    vectorstore = Chroma.from_documents(documents, embeddings, collection_name=\"restaurant_info\")\n",
    "\n",
    "    return vectorstore\n",
    "\n",
    "# Run this function to set up the vector database\n",
    "vectorstore = setup_vector_db()\n",
    "print(\"Vector database has been set up successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restaurant Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1725796537.975955 10816432 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n",
      "I0000 00:00:1725796537.976196 10816432 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to our restaurant chatbot! How can I assist you today?\n",
      "Chatbot: The best reviewed item is the Lasagna. \n",
      "\n",
      "Chatbot: Yes, the Lasagna is available now. Would you like to place an order for it? \n",
      "\n",
      "Chatbot: The price of the Lasagna is $16.37. \n",
      "\n",
      "Chatbot: I can place an order for the Lasagna for you. Could you please tell me your name and phone number so I can place the order? \n",
      "\n",
      "Chatbot: Please provide me with your delivery address so I can place your order for the Lasagna. \n",
      "\n",
      "Chatbot: I'm sorry, I don't have any information about table numbers.  I can help you place an order for the Lasagna if you'd like.  Do you have a delivery address? \n",
      "\n",
      "Chatbot: I understand you'd like to place an order for the Lasagna. To complete your order, I need a delivery address or table number. Please provide me with that information. \n",
      "\n",
      "Chatbot: I'm sorry, but I don't have any information about a delivery address. I can help you with information about our menu items, prices, and availability.  Do you have any other questions? \n",
      "\n",
      "Chatbot: I understand you're trying to place an order for the Lasagna. To complete your order, I need a delivery address. Please provide the full address so I can place your order. \n",
      "\n",
      "Thank you for using our chatbot. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import Runnable\n",
    "from langchain.schema.runnable.config import RunnableConfig\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# Initialize Gemini model\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    google_api_key=\"YOUR_GOOGLE_API_KEY\",\n",
    ")\n",
    "\n",
    "# Set up memory\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "# Set up retrieval chain with memory\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "# Create a prompt template\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a helpful restaurant chatbot. Use the provided context and chat history to answer customer queries about menu items, prices, availability, and reviews. You can also place orders for customers.\n",
    "    \n",
    "    Context: {context}\n",
    "    Chat History: {chat_history}\n",
    "    \n",
    "    Remember to be polite and helpful. If you need to place an order, use the place_order function.\"\"\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# Create the chain\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Function to run the chatbot\n",
    "def run_chatbot(user_input: str) -> str:\n",
    "    # Retrieve relevant information from the vector database and get response\n",
    "    result = qa_chain({\"question\": user_input})\n",
    "    context = result['answer']\n",
    "    chat_history = memory.chat_memory.messages\n",
    "\n",
    "    # Generate final response using the retrieved context and chat history\n",
    "    response = chain.invoke({\n",
    "        \"input\": user_input,\n",
    "        \"context\": context,\n",
    "        \"chat_history\": chat_history\n",
    "    })\n",
    "    return response\n",
    "\n",
    "# Main interaction loop\n",
    "print(\"Welcome to our restaurant chatbot! How can I assist you today?\")\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in ['exit', 'quit', 'bye']:\n",
    "        print(\"Thank you for using our chatbot. Goodbye!\")\n",
    "        break\n",
    "    \n",
    "    response = run_chatbot(user_input)\n",
    "    print(\"Chatbot:\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
