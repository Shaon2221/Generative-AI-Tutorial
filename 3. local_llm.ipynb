{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (1.32.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from openai) (2.7.3)\n",
      "Requirement already satisfied: sniffio in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from openai) (4.12.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\" Calculus, which can be broadly divided into differential calculus and integral calculus, is the mathematical study of change. The primary motivation for its development was to solve problems related to motion and areas under curves in physics. Here's a simplified overview of the logic behind both branches:\\n\\n1. Differential Calculus: \\nDifferential calculus deals with rates at which quantities change, such as velocity (the rate of change of position) or acceleration (the rate of change of velocity). The foundational concept in differential calculus is the derivative. A derivative represents a slope of a function, describing how one quantity changes concerning another. This was first introduced by Isaac Newton and Gottfried Wilhelm Leibniz during their development of infinitesimal calculus.\\n\\nThe logic behind finding derivatives involves analyzing small increments or differences between two points on a curve. If we consider a curve f(x) at point x, the derivative is defined as the limit: lim_(h->0) (f(x+h)-f(x))/h. This formula represents an infinitesimal change in y (the difference quotient), and when h approaches zero, it becomes the slope of a tangent line to the curve at point x.\\n\\n2. Integral Calculus: \\nIntegral calculus is concerned with accumulation or aggregation – how quantities add up over time. The fundamental concept in integral calculus is the integral. An integral represents the area under a curve, which can be interpreted as a total change of quantity between two points on that function. Again, this was first developed by Newton and Leibniz.\\n\\nThe logic behind finding integrals involves summing up infinitely small areas (infinitesimals) to compute the total area under a given curve. This concept is represented in the definite integral: ∫(a to b) f(x) dx, which calculates the accumulated quantity as x ranges from 'a' to 'b'. To determine the value of this integral, we can approximate it using Riemann sums, where we divide the area under the curve into rectangles (or other shapes), sum their areas and then take a limit as the size of these subdivisions approaches zero.\\n\\nOverall, calculus provides tools for understanding how quantities change over time or space by analyzing rates of change (differential calculus) and accumulation (integral calculus). Together, they have become essential in various fields like physics, engineering, economics, biology, and more.\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# Example: reuse your existing OpenAI setup\n",
    "from openai import OpenAI\n",
    "\n",
    "# Point to the local server\n",
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"anything\")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"LM Studio Community/Phi-3-mini-4k-instruct-GGUF\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"Act as helpful assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"what is logic behind calculus?\"}\n",
    "  ],\n",
    "  temperature=0.7,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Calculus, which can be broadly divided into differential calculus and integral calculus, is the mathematical study of change. The primary motivation for its development was to solve problems related to motion and areas under curves in physics. Here's a simplified overview of the logic behind both branches:\\n\\n1. Differential Calculus: \\nDifferential calculus deals with rates at which quantities change, such as velocity (the rate of change of position) or acceleration (the rate of change of velocity). The foundational concept in differential calculus is the derivative. A derivative represents a slope of a function, describing how one quantity changes concerning another. This was first introduced by Isaac Newton and Gottfried Wilhelm Leibniz during their development of infinitesimal calculus.\\n\\nThe logic behind finding derivatives involves analyzing small increments or differences between two points on a curve. If we consider a curve f(x) at point x, the derivative is defined as the limit: lim_(h->0) (f(x+h)-f(x))/h. This formula represents an infinitesimal change in y (the difference quotient), and when h approaches zero, it becomes the slope of a tangent line to the curve at point x.\\n\\n2. Integral Calculus: \\nIntegral calculus is concerned with accumulation or aggregation – how quantities add up over time. The fundamental concept in integral calculus is the integral. An integral represents the area under a curve, which can be interpreted as a total change of quantity between two points on that function. Again, this was first developed by Newton and Leibniz.\\n\\nThe logic behind finding integrals involves summing up infinitely small areas (infinitesimals) to compute the total area under a given curve. This concept is represented in the definite integral: ∫(a to b) f(x) dx, which calculates the accumulated quantity as x ranges from 'a' to 'b'. To determine the value of this integral, we can approximate it using Riemann sums, where we divide the area under the curve into rectangles (or other shapes), sum their areas and then take a limit as the size of these subdivisions approaches zero.\\n\\nOverall, calculus provides tools for understanding how quantities change over time or space by analyzing rates of change (differential calculus) and accumulation (integral calculus). Together, they have become essential in various fields like physics, engineering, economics, biology, and more.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (0.2.3)\n",
      "Requirement already satisfied: langchain_community in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (0.2.4)\n",
      "Requirement already satisfied: langchain_core in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (0.2.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from langchain) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from langchain) (0.2.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from langchain) (0.1.74)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from langchain) (2.7.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from langchain) (8.3.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from langchain_community) (0.6.6)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from langchain_core) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from langchain_core) (23.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain_core) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (4.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from requests<3,>=2->langchain) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/shaonsikder/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain_community langchain_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.1\",temperature=0.2)\n",
    "\n",
    "messages = [SystemMessage(content= \"Act as helpful assistant\"), \n",
    "            HumanMessage(content =\"what is logic behind calculus?\")]\n",
    "model_response = llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Calculus is a branch of mathematics that deals with the study of continuous change, particularly in the context of functions and limits. The logic behind calculus can be broken down into several key concepts:\\n\\n1. **Limits**: Calculus begins with the concept of limits, which allows us to understand how a function behaves as its input gets arbitrarily close to a certain value. Limits are used to define the basic operations of calculus, such as differentiation and integration.\\n2. **Differentiation**: Differentiation is the process of finding the rate at which a function changes as its input changes. This is done by calculating the derivative of the function, which represents the slope of the tangent line to the graph of the function at a given point.\\n3. **Integration**: Integration is the process of finding the area under a curve or the accumulation of a quantity over an interval. This is done by calculating the definite integral of the function, which represents the total amount of change in the function's output as its input changes.\\n\\nThe logic behind calculus can be understood through several key principles:\\n\\n* **The concept of infinitesimal**: Calculus relies on the idea that we can consider infinitely small changes in a quantity. This allows us to study the behavior of functions at specific points or intervals.\\n* **The concept of accumulation**: Integration is based on the idea that the area under a curve can be thought of as the accumulation of an infinite number of infinitesimal rectangles.\\n* **The Fundamental Theorem of Calculus**: This theorem states that differentiation and integration are inverse processes, meaning that they cancel each other out. It also provides a way to compute definite integrals using antiderivatives.\\n\\nSome key mathematical concepts that underlie calculus include:\\n\\n* **Real numbers**: Calculus deals with real numbers, which are the set of all rational and irrational numbers.\\n* **Functions**: A function is a relation between a set of inputs (called the domain) and a set of outputs (called the range).\\n* **Graphs**: The graph of a function is a visual representation of its behavior.\\n\\nSome key logical principles that underlie calculus include:\\n\\n* **The principle of mathematical induction**: This principle allows us to prove statements about all positive integers by showing that they hold for an arbitrary positive integer.\\n* **The concept of proof by contradiction**: This principle involves assuming the opposite of what we want to prove and then showing that this assumption leads to a logical contradiction.\\n\\nOverall, calculus is built on a foundation of mathematical concepts and principles that allow us to study continuous change and accumulation.\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function for printing hello world 10 times\n",
    "def hello_world():\n",
    "    \"\"\"\n",
    "    Prints 'Hello World' 10 times.\n",
    "    \"\"\"\n",
    "    for i in range(10):\n",
    "        print(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "import requests\n",
    "import openai\n",
    "from prompt import *\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# List of proxies\n",
    "proxies = [\n",
    "    \"http://192.168.10.42:3128\",\n",
    "    \"http://192.168.10.43:3128\",\n",
    "    \"http://192.168.10.44:3128\",\n",
    "    \"http://192.168.10.45:3128\",\n",
    "    \"http://192.168.10.49:3128\",\n",
    "    \"http://192.168.10.50:3128\",\n",
    "    \"http://192.168.10.51:3128\",\n",
    "    \"http://192.168.10.53:3128\",\n",
    "]\n",
    "\n",
    "# Choose a proxy (e.g., the first one in the list)\n",
    "proxy = proxies[0]\n",
    "\n",
    "# Configuration for OpenAI API\n",
    "openai.api_base = \"http://localhost:1234/v1\"\n",
    "openai.api_key = \"not-needed\"\n",
    "\n",
    "# Set up environment variables for the proxy\n",
    "# os.environ[\"http_proxy\"] = proxy\n",
    "# os.environ[\"https_proxy\"] = proxy\n",
    "# Set the Google API key\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"Put your API keys here\"\n",
    "\n",
    "# Initialize the model\n",
    "google_llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-latest\", convert_system_message_to_human=True)\n",
    "\n",
    "#  mistral:7b-instruct\n",
    "# Initialize the LLM model\n",
    "# llm = Ollama(model=\"llama3:8b-instruct-q6_K\", stop=[\"<|im_end|>\\n\"])\n",
    "# llm = ChatOllama(model=\"mistral:7b-instruct\", temperature=0)\n",
    "# llm = ChatOllama(model=\"codellama:34b-code-q2_K\", temperature=0)\n",
    "# llm = ChatOllama(model=\"deepseek-coder:6.7b-instruct\", temperature=0)\n",
    "llm = ChatOllama(model=\"starcoder2:15b-instruct\", temperature=0)\n",
    "\n",
    "def get_model_response(user_prompt, system_prompt):\n",
    "    # NOTE: No f string and no whitespace in curly braces\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=system_prompt\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content=user_prompt\n",
    "    )\n",
    "    ]\n",
    "\n",
    "    # Modified invoking the model\n",
    "    chat_model_response = llm.invoke(messages)\n",
    "    response = chat_model_response.content\n",
    "    return response\n",
    "\n",
    "class OllamaRequest(BaseModel):\n",
    "    model: str\n",
    "    prompt: str\n",
    "\n",
    "class PromptRequest(BaseModel):\n",
    "    system_prompt: str\n",
    "    user_prompt: str\n",
    "\n",
    "# Define the request body schema\n",
    "class MessageRequest(BaseModel):\n",
    "    system_message: str\n",
    "    user_message: str\n",
    "\n",
    "# Define the response schema\n",
    "class MessageResponse(BaseModel):\n",
    "    response: str\n",
    "\n",
    "@app.post(\"/gemini-api\", response_model=MessageResponse)\n",
    "async def chat_endpoint(request: MessageRequest):\n",
    "    try:\n",
    "        # Prepare the messages\n",
    "        system_message = SystemMessage(content=request.system_message)\n",
    "        human_message = HumanMessage(content=request.user_message)\n",
    "        \n",
    "        # Get the response from the LLM\n",
    "        response = google_llm([system_message, human_message])\n",
    "        \n",
    "        # Return the response content\n",
    "        return MessageResponse(response=response.content)\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "@app.post(\"/generate\")\n",
    "def generate_text(request: OllamaRequest):\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "    }\n",
    "\n",
    "    payload = request.dict()\n",
    "    data = {\n",
    "        \"model\": payload['model'],\n",
    "        \"prompt\": payload['prompt'],\n",
    "        \"stream\": False,\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        response_text  = response.text\n",
    "        data = json.loads(response_text)\n",
    "        actual_response = data['response']\n",
    "        return {\"response\": actual_response}\n",
    "    else:\n",
    "        raise HTTPException(status_code=response.status_code, detail=response.text)\n",
    "\n",
    "@app.post(\"/generate-response/\")\n",
    "async def generate_response(prompt_request: PromptRequest):\n",
    "    system_prompt = prompt_request.system_prompt\n",
    "    user_prompt = prompt_request.user_prompt\n",
    "    return {\"response\": get_model_response(system_prompt, user_prompt)}\n",
    "\n",
    "\n",
    "@app.post(\"/llama3-70b-api/\")\n",
    "async def generate_llama_response(prompt_request: PromptRequest):\n",
    "    system_prompt = prompt_request.system_prompt\n",
    "    user_prompt = prompt_request.user_prompt\n",
    "    completion =  openai.ChatCompletion.create(\n",
    "        model=\"local-model\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "@app.get(\"/codellama-34b-api/\")\n",
    "async def generate_codellama_response(): #prompt_request: PromptRequest\n",
    "    # system_prompt = prompt_request.system_prompt\n",
    "    # user_prompt = prompt_request.user_prompt\n",
    "    return {\"response\": get_model_response(system_prompt, user_prompt)}\n",
    "\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    logging.basicConfig(level=logging.DEBUG)\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000, log_level=\"debug\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
